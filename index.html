<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <link href="https://cdn.jsdelivr.net/npm/daisyui@3.4.0/dist/full.css" rel="stylesheet" type="text/css" />
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body>
    <section class="bg-[#141A31] py-10">
        <div class="grid grid-cols-1 lg:grid-cols-2 justify-center items-center">
            <div class="flex flex-col lg:flex-row items-center justify-center relative border-4 border-red-600">
                <div class="relative w-full lg:w-1/2">
                    <input id="inputField" class="px-3 py-4 text-sm lg:text-xl w-full border-none" type="text" placeholder="Describe what you want to directly click!!">
                    <!-- Modified button click event for voice recognition and generating response -->
                    <button onclick="startVoiceRecognition()" class="absolute right-0 top-0 bottom-0">
                        <a class="btn-primary px-2 lg:px-2 py-2 lg:py-3 sans mr-2"> <i class="fa-solid fa-microphone-lines text-white text-xs md:text-sm lg:text-base "></i> GENERATE</a>
                    </button>
                </div>
            </div>
            
            <div class="flex items-center justify-center">
                <textarea id="outputArea" class="bg-white text-black border-4 border-red-600" cols="30" rows="10"></textarea>
            </div>
        </div>
    </section>
    
    <!-- JavaScript code -->
    <script>
        // Function to handle voice recognition and generating response
        function startVoiceRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            const recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                document.getElementById('inputField').value = transcript;
                
                // Generate response when voice input is captured
                await generateResponse();
            };

            recognition.start();
        }

        // Function to generate response
        async function generateResponse() {
            const apiKey = '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';
            const prompt = document.getElementById('inputField').value;
            
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify({
                    model: 'gpt-3.5-turbo',
                    messages: [
                        { role: 'system', content: 'You are a helpful assistant.' },
                        { role: 'user', content: prompt }
                    ]
                })
            });
            
            const responseData = await response.json();
            const responseText = responseData.choices[0].message.content;
            document.getElementById('outputArea').value = responseText;
        }
    </script>
</body>
</html>
